<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mahmoud Nazzal - Recent Projects">
    <title>Mahmoud Nazzal | Recent Projects</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #2b2d31;
            color: #ffffff;
            margin: 0;
            padding: 0;
            font-size: 0.85rem;
        }
        header {
            background: #1e2124;
            padding: 15px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        header h1 {
            margin: 0;
            font-size: 1.2rem;
            color: #ffffff;
        }
        nav a {
            color: #ffffff;
            margin-left: 15px;
            text-decoration: none;
            font-size: 0.85rem;
        }
        .container {
            max-width: 1100px;
            margin: 20px auto;
            padding: 20px;
            background: #2b2d31;
        }
        .project {
            background: #1e2124;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            border: 1px solid #3a71c1;
        }
        .project h2 {
            font-size: 1.3rem;
            color: #3a71c1;
            margin-bottom: 10px;
        }
        .project img {
            width: 100%;
            margin: 10px 0;
            border-radius: 5px;
        }
        .project p {
            margin: 10px 0;
        }
        .reference {
            font-style: italic;
            color: #aaaaaa;
        }
    </style>
</head>
<body>
    <header>
        <h1>Recent Projects</h1>
        <nav>
            <a href="index.html">Home</a>
            <a href="about.html">About</a>
            <a href="research.html">Research</a>
            <a href="experience.html">Experience</a>
            <a href="education.html">Education</a>
            <a href="teaching.html">Teaching</a>
            <a href="awards.html">Awards</a>
            <a href="technical_skills.html">Technical Skills</a>
            <a href="M_Nazzal_CV_Oct_2024_public.pdf" target="_blank">CV</a>
            <a href="#contact">Contact</a>
        </nav>
    </header>

    <div class="container">
        <!-- Project 1: PromSec -->
    <div class="project">
        <h2>PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)</h2>
        <p><strong>Problem:</strong> LLMs tend to generate functional but insecure code.</p>
        <p><strong>Objective:</strong> Optimize prompts to generate secure functional code with LLMs.</p>
        <p><strong>Key Contributions:</strong></p>
        <ul>
            <li> Graph generative adversarial network (gGAN) + LLM loop to reduce vulnerabilities and maintain functionality.</li>
            <li>Contrastive learning for dual-objective optimization.</li>
            <li>Transferable prompts across LLMs and vulnerabilities.</li>
        </ul>
        <p><strong>Methodology:</strong> gGAN fixes code vulnerabilities, LLM improves prompts, and iterative loop for optimizing code security.</p>
        <p><strong>Key Results:</strong> Enhances security while maintaining functionality, reduces operational time and costs significantly, prompts work across languages and LLMs, reduces vulnerabilities in generated code.</p>
        <img src="figs/promsec_animation.gif" alt="PromSec Figure">
        
        <h3>Papers:</h3>
        <ul>
            <li>
                [1] M. Nazzal, I. Khalil, A. Khreishah, and N.H. Phan, “PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs),” in 31st ACM Conference on Computer and Communications Security (CCS 2024), Salt Lake City, UT, USA, Oct. 2024.
                <a href="https://arxiv.org/pdf/2409.12699" target="_blank">Arxiv Preprint</a> |
                <a href="https://github.com/mahmoudkanazzal/PromSec" target="_blank">Artifacts</a>
            </li>
            <li>
                [2] T.K. Ton, N. Nguyen, M. Nazzal, A. Khreishah, C. Borcea, N.H. Phan, R. Jin, I. Khalil, and Y. Shen, “Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code,” 31st ACM Conference on Computer and Communications Security (CCS 2024), Salt Lake City, UT, USA, Oct. 2024.
                <a href="https://arxiv.org/abs/2409.07368" target="_blank">Preprint</a> |
                <a href="https://sgcode.codes/" target="_blank">Demo Website</a>
            </li>
            <li>
                [3] M. Nazzal, I. Khalil, A. Khreishah, and N.H. Phan, “Method and System for Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models,” US Patent, Application No.: US63/561,573, Washington, D.C., USA, Filing date: Mar. 5, 2024.
            </li>
        </ul>
    </div>
</div>



        <!-- Project 2: MintA -->
        <div class="project">
            <h2>Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection</h2>
            <p><strong>Problem:</strong> Need for a new adversarial attack on multiple instances to evade malicious domain detection.</p>
            <p><strong>Objective:</strong> Develop MintA, an attack that evades GNN-based malicious domain detection by optimizing multiple domain manipulations.</p>
            <p><strong>Key Contributions:</strong></p>
            <ul>
                <li>MintA: A multi-instance evasion attack optimizing node perturbations for evasiveness.</li>
                <li>Black-box attack requiring no knowledge of model parameters.</li>
            </ul>
            <p><strong>Methodology:</strong> Construct a surrogate model using black-box access, optimize node and edge perturbations to maximize evasiveness, implement perturbations through domain and IP modifications.</p>
            <p><strong>Results:</strong> Achieves over 80% success rate in evading detection, bypasses outlier detection and graph purification defenses.</p>
            <img src="figs/minta_animation.gif" alt="MintA Figure">
            <p class="reference">[2] M. Nazzal, I. Khalil, A. Khreishah, N. Phan, & Y. Ma, “Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection,” in 2024 IEEE Symposium on Security and Privacy (SP), May 2024.</p>
        </div>

        <!-- Project 3: SA-DS -->
        <div class="project">
            <h2>SA-DS: A Dataset for Large Language Model-Driven AI Accelerator Design Generation</h2>
            <p><strong>Problem:</strong> Lack of specialized datasets for AI-driven accelerator design.</p>
            <p><strong>Objective:</strong> Introduce SA-DS for LLM-based DNN hardware design.</p>
            <p><strong>Key Contributions:</strong></p>
            <ul>
                <li>SA-DS: Diverse array designs using Gemmini.</li>
                <li>An envisioned framework for optimizing hardware design generation.</li>
            </ul>
            <p><strong>Methodology:</strong> Data from Gemmini in Chisel, supports LLM fine-tuning and multi-shot learning, quality check using Verilator.</p>
            <p><strong>Results:</strong> 100% pass rate with multi-shot learning, fewer revisions, better workflow.</p>
            <img src="figs/sads_figure.png" alt="SA-DS Figure">
            <p class="reference">[3] D. Vungarala*, M. Nazzal*, M. Morsali, C. Zhang, A. Ghosh, A. Khreishah, and S. Angizi, “SA-DS: A Dataset for Large Language Model-Driven AI Accelerator Design Generation,” IEEE International Symposium on Circuits and Systems (ISCAS) 2025. [Accepted].</p>
            <p class="reference">[4] arXiv preprint: arXiv:2404.10875. https://doi.org/10.48550/arXiv.2404.10875</p>
        </div>

                <!-- Work 4: Deepfake Detection -->
        <div class="project">
            <h2>Work 4: Deepfake Detection with Vision-Language Model Explanations and GNN Integration</h2>
            <canvas id="projectCanvas4"></canvas>
            <p><strong>Problem:</strong> Growing challenge of realistic deepfakes that threaten media authenticity. Existing methods struggle with robustness and generalization.</p>
            <p><strong>Objective:</strong> Combines visual and AI-generated textual analysis for improved detection.</p>
            <p><strong>Key Contributions:</strong></p>
            <ul>
                <li>Visual-Textual Integration: Fuses image analysis with AI-generated text insights.</li>
                <li>Robust to Adversarial Attacks: Withstands customized deepfake techniques.</li>
                <li>Strong Generalization: Adapts to diverse deepfake sources and models.</li>
            </ul>
            <p><strong>Methodology:</strong></p>
            <ul>
                <li>Divides images into components and generates detailed text explanations.</li>
                <li>Uses a dual-layer analysis with graph techniques to merge visual and textual data.</li>
            </ul>
            <p><strong>Main Results:</strong> Enhanced Accuracy: Achieves higher recall, reducing false negatives. Stability Under Attack: Lowers performance drop from 13.3% to 1.5%. Scalable Solution: Effective across varied deepfake scenarios.</p>
            <p><strong>Note:</strong> Summary presented with care for privacy, as the paper is under double-blind review.</p>
            <img src="figs/vigitext_animation.gif" alt="Deepfake Detection Illustration">
        </div>

        <!-- Work 5: Semi-decentralized Inference in hetGNNs -->
        <div class="project">
            <h2>Work 5: Semi-decentralized Inference in hetGNNs for Traffic Demand Prediction: An Edge-Computing Approach</h2>
            <canvas id="projectCanvas5"></canvas>
            <p><strong>Problem:</strong> Scalability issues in GNN-based traffic forecasting due to high message passing overhead.</p>
            <p><strong>Objective:</strong> Create a scalable, efficient traffic forecasting method using semi-decentralized hetGNN-LSTM.</p>
            <p><strong>Key Contributions:</strong></p>
            <ul>
                <li>HetGNN-LSTM: Uses multiple relationships for accurate predictions.</li>
                <li>Semi-decentralized: Uses cloudlets to reduce overhead.</li>
                <li>Adaptive Assignment: Minimizes inter-cloudlet communication.</li>
            </ul>
            <p><strong>Methodology:</strong></p>
            <ul>
                <li>HetGNN-LSTM: Learns from heterogeneous data and time dependencies.</li>
                <li>Semi-Decentralized: Cloudlets manage subgraphs to reduce load.</li>
                <li>Adaptive Assignment: Uses clustering to reduce inter-cloudlet communication.</li>
            </ul>
            <p><strong>Main Results:</strong> High accuracy compared to existing models. Inference time reduced by an order of magnitude. Improved scalability and reduced costs.</p>
            <img src="figs/hetgnn_inference.png" alt="hetGNN Inference Illustration">
            <p><strong>References:</strong></p>
            <p>[8] M. Nazzal, A. Khreishah, J. Lee, S. Angizi, A. Al-Fuqaha, and M. Guizani, “Semi decentralized Inference in Heterogeneous Graph Neural Networks for Traffic Demand Forecasting: An Edge-Computing Approach”, IEEE Transactions on Vehicular Technology, Jan. 2024.</p>
        </div>

        <a href="index.html" class="back-link"><i class="fas fa-arrow-left"></i> Back to Homepage</a>
    </div>
</body>
</html>
